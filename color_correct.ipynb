{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fcn import FCN\n",
    "from utils import get_session\n",
    "from config import *\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import os\n",
    "import os.path as osp\n",
    "from glob import glob\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images into memory.\n",
    "imgps = glob(\"./original_images/*.jpg\")\n",
    "print(len(imgps))\n",
    "\n",
    "images = []\n",
    "filenames = []\n",
    "for imgp in imgps[:]:\n",
    "    print(imgp)\n",
    "    img = cv2.imread(imgp)\n",
    "    # reverse gamma correction for sRGB\n",
    "    img = (img / 255.0) ** 2.2 * 65536\n",
    "    images.append(img)\n",
    "    \n",
    "    filenames.append(osp.basename(imgp))\n",
    "\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test inference on multiple images.\n",
    "tf.reset_default_graph()  # allows multiple executions of this block\n",
    "\n",
    "ckpt = \"pretrained/colorchecker_fold1and2.ckpt\"\n",
    "with get_session() as sess:\n",
    "    fcn = FCN(sess=sess, name=ckpt)\n",
    "    fcn.load_absolute(ckpt)\n",
    "    fcn.test_external(images=images, fns=filenames, show=False, write_compare=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images from URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2311"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifest = json.load(open(\"match_dataset_combined.json\"))\n",
    "len(manifest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"match_images_internal\"\n",
    "list_name = \"url.list\"\n",
    "\n",
    "!mkdir {target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [url for d in manifest for url in d[target]]\n",
    "print(len(urls))\n",
    "urls = list(set(urls))\n",
    "print(len(urls))\n",
    "\n",
    "with open(osp.join(target, list_name), \"w\") as f:\n",
    "    for url in urls:\n",
    "        f.write(url+\"\\n\")\n",
    "\n",
    "urls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat ./match_images_internal/url.list | parallel --gnu \"wget {} --directory-prefix ./match_images_internal/\"\n"
     ]
    }
   ],
   "source": [
    "# Will take 10 minutes.\n",
    "cmd = 'cat ./{}/{} | parallel --gnu -j 20 \"wget {} --directory-prefix ./{}/ -T 5 -t 1\"'.format(target, list_name, \"{}\", target)\n",
    "print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images from urls.\n",
    "for url in urls[100:102]:\n",
    "    print(url)\n",
    "    url_response = urllib.urlopen(url)\n",
    "    img = cv2.imdecode(np.array(bytearray(url_response.read()), dtype=np.uint8), -1)\n",
    "    # reverse gamma correction for sRGB\n",
    "    img = (img / 255.0) ** 2.2 * 65536\n",
    "    images.append(img)\n",
    "    \n",
    "    filenames.append(osp.basename(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_external(self, imgpaths, scale=1.0, show=True, save_prefix=\"cc_outputs\", write=False, write_compare=False):\n",
    "    illums = []\n",
    "    confidence_maps = []\n",
    "    errors = []\n",
    "    for i, imgp in enumerate(imgpaths):\n",
    "        filename = osp.basename(imgp)+\".jpg\"  # force save as jpg\n",
    "        print \"\"\n",
    "        print i, filename\n",
    "        \n",
    "        try:\n",
    "            img = cv2.imread(imgp)\n",
    "        except Exception as e:\n",
    "            print(\"ERROR can't read image {}\\n{}\".format(filename, e))\n",
    "            errors.append(imgp)\n",
    "            continue\n",
    "        \n",
    "        if img is None:\n",
    "            print(\"ERROR read None for {}\".format(filename))\n",
    "            errors.append(imgp)\n",
    "            continue\n",
    "        \n",
    "        # reverse gamma correction for sRGB\n",
    "        img_linear = (img / 255.0) ** 2.2 * 65536\n",
    "        \n",
    "        if scale != 1.0:\n",
    "            img_linear = cv2.resize(img_linear, (0, 0), fx=scale, fy=scale)\n",
    "        \n",
    "        shape = img_linear.shape[:2]    \n",
    "        if shape not in self.test_nets:\n",
    "            #print(\"shape {}\".format(shape))\n",
    "            \n",
    "            aspect_ratio = 1.0 * shape[1] / shape[0]\n",
    "            if aspect_ratio < 1:\n",
    "                target_shape = (MERGED_IMAGE_SIZE, MERGED_IMAGE_SIZE * aspect_ratio)\n",
    "            else:\n",
    "                target_shape = (MERGED_IMAGE_SIZE / aspect_ratio, MERGED_IMAGE_SIZE)\n",
    "            \n",
    "            target_shape = tuple(map(int, target_shape))\n",
    "\n",
    "            test_net = {}\n",
    "            test_net['illums'] = tf.placeholder(\n",
    "                tf.float32, shape=(None, 3), name='test_illums')\n",
    "            test_net['images'] = tf.placeholder(\n",
    "                tf.float32, shape=(None, shape[0], shape[1], 3), name='test_images')\n",
    "            with tf.variable_scope(\"FCN\", reuse=True):\n",
    "                try:\n",
    "                    test_net['pixels'] = FCN.build_branches(test_net['images'], 1.0)\n",
    "                except ValueError as e:\n",
    "                    print(\"ERROR {}\".format(e))\n",
    "                    errors.append(imgp)\n",
    "                    continue\n",
    "\n",
    "                test_net['est'] = tf.reduce_sum(test_net['pixels'], axis=(1, 2))\n",
    "            test_net['merged'] = get_visualization(\n",
    "                test_net['images'], test_net['pixels'], test_net['est'],\n",
    "                test_net['illums'], target_shape)\n",
    "            self.test_nets[shape] = test_net\n",
    "            \n",
    "        test_net = self.test_nets[shape]\n",
    "\n",
    "        pixels, est, merged = self.sess.run(\n",
    "            [test_net['pixels'], test_net['est'], test_net['merged']],\n",
    "            feed_dict={\n",
    "                test_net['images']: img_linear[None, :, :, :],\n",
    "                test_net['illums']: [[1, 1, 1]]\n",
    "            }\n",
    "        )\n",
    "        est = est[0]\n",
    "        est /= np.linalg.norm(est)\n",
    "\n",
    "        pixels = pixels[0]\n",
    "        confidences = np.linalg.norm(pixels, axis=2)\n",
    "        confidence_maps.append(confidences)\n",
    "        ind = int(confidences.flatten().shape[0] * 0.95)\n",
    "        print(\"Confidence: {:0.1f} mean, {:0.1f} max, {:0.1f} 95%\".format(\n",
    "            confidences.mean(),\n",
    "            confidences.max(),\n",
    "            sorted(confidences.flatten())[ind]))\n",
    "        merged = merged[0]\n",
    "        illums.append(est)\n",
    "\n",
    "        if show:\n",
    "            cv2.imshow('Ret', merged[:, :, ::-1])\n",
    "            k = cv2.waitKey(0) % (2**20)\n",
    "\n",
    "        try:\n",
    "            os.makedirs(save_prefix)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        corrected = np.power(img_linear[:,:,::-1] / 65535 / est[None, None, :] * np.mean(est), 1/2.2)[:,:,::-1]\n",
    "        if show:\n",
    "            cv2.imshow(\"corrected\", corrected)\n",
    "            cv2.waitKey(0)\n",
    "\n",
    "        corrected = corrected * 255.0\n",
    "        output_img = corrected\n",
    "        if write_compare:\n",
    "            orig_img = img #np.power(img / 65535, 1/2.2) * 255\n",
    "            output_img = np.concatenate((orig_img, corrected), axis=1)\n",
    "\n",
    "        cv2.imwrite(osp.join(save_prefix, 'corrected_%s' % filename), output_img, )\n",
    "\n",
    "    return illums, confidence_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6414"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_ind = 0\n",
    "print(start_ind)\n",
    "imgpaths = glob(\"./match_images/*\")[start_ind:]\n",
    "len(imgpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test inference on multiple images.\n",
    "from summary_utils import get_visualization\n",
    "tf.reset_default_graph()  # allows multiple executions of this block\n",
    "\n",
    "ckpt = \"pretrained/colorchecker_fold1and2.ckpt\"\n",
    "with get_session() as sess:\n",
    "    fcn = FCN(sess=sess, name=ckpt)\n",
    "    fcn.load_absolute(ckpt)\n",
    "    illums, confidence_maps = test_external(fcn, imgpaths=imgpaths, save_prefix=\"match_colorcorrected\", show=False, write_compare=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of image which will not load.\n",
    "img = cv2.imread(imgpaths[1])\n",
    "img is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'> (1, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "# Example of an image which does not error on loading, but also does not load.\n",
    "img = cv2.imread(imgpaths[33])\n",
    "print type(img), img.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
